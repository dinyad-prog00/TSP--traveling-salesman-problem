\section{Algorithmes implémentés}
Pour ce TP, nous avons implémenté les différents algorithmes de descente et les recherches locales moins strictes que les
descentes : recherche locale itérée (ILS : Iterated Local Search) et Sampled Walk (SW).

\subsection{Les descentes}
Les algorithmes de descente sont des méthodes heuristiques qui visent à améliorer itérativement une solution initiale en explorant son voisinage. Les algorithmes de descente peuvent être classés en différentes catégories en fonction de la relation de voisinage et de la manière dont ils choisissent le voisin. Les trois principaux types d'algorithmes de descente sont le meilleur voisin, le premier améliorant et le pire voisin.

\subsubsection{Les relation de voisinage}
\begin{itemize}
	\item Swap : elle consiste à échanger les positions de deux villes dans le parcours du voyageur.
	\item 2-opt : elle  consiste à inverser l'ordre des villes entre deux positions du parcours du voyageur.
\end{itemize}

\subsubsection{Choix de voisin}
\begin{itemize}
	\item Meilleur améliorant
	
	L'algorithme du meilleur améliorant (Algo~\ref{algo:meilleur_aml}) explore tous les voisins d'une solution et sélectionne celui qui offre la meilleure amélioration en termes de fonction objectif.
	
	Dans les pseudos codes nous tenons seulement compte des arguments importants pour la compréhension.
	
	\begin{algorithm}[H]
		\caption{Meilleur améliorant}
		\label{algo:meilleur_aml}
		\begin{algorithmic}[1]
			\Require{$ voisins  = $ voisins générés avec swap ou 2-opt}
			\Require{$solution$ : solution actuelle}
			\Ensure{$meilleur\_voisin$}
			\Statex
			
			\Function{best\_improver}{$\mathbf{solution}$, $\mathbf{voisins}$}
			\State {$meilleur\_voisin$ $\gets$ {$NULL$}}
			\State {$cur\_cost$ $\gets$ {$cost(solution)$}}

			\For { \textbf{each} $voisin$ \textbf{in}
				 $voisins$}                    
			\If{$cost(voisin) < cur\_cost$}  
				\State {$meilleur\_voisin$ $\gets$ {$voisin$}}
				\State {$cur\_cost$ $\gets$ {$cost(voisin)$}}
			\EndIf
			\EndFor
			\State \Return {$meilleur\_voisin$}
			\EndFunction
			
		\end{algorithmic}
	\end{algorithm}
	
	\item Premier améliorant
	
	Contrairement à l'algorithme du meilleur améliorant, l'algorithme du premier améliorant (Algo ~\ref{algo:first_improver}) s'arrête dès qu'il trouve le premier voisin qui améliore la solution courante.
	
		\begin{algorithm}[H]
		\caption{Premier améliorant}
		\label{algo:first_improver}
		\begin{algorithmic}[1]
			\Require{$ voisins  = $ voisins générés avec swap ou 2-opt}
			\Require{$solution$ : solution actuelle}
			\Ensure{$premier\_ameliorant$}
			\Statex
			
			\Function{first\_improver}{$\mathbf{solution}$, $\mathbf{voisins}$}
			\State {$cur\_cost$ $\gets$ {$cost(solution)$}}
			
			\For { \textbf{each} $voisin$ \textbf{in}
				$voisins$}                    
			\If{$cost(voisin) < cur\_cost$}  
			\State \Return {$voisin$}
			\EndIf
			\EndFor
		\State \Return {$NULL$}
			\EndFunction
			
		\end{algorithmic}
	\end{algorithm}
	
	\item Pire améliorant
	L'algorithme du pire améliorant (Algo ~\ref{algo:worst_improver}) explore tous les voisins d'une solution et sélectionne celui qui offre la pire amélioration.
	
		\begin{algorithm}[H]
		\caption{Pire améliorant}
		\label{algo:worst_improver}
		\begin{algorithmic}[1]
			\Require{$ voisins  = $ voisins générés avec swap ou 2-opt}
			\Require{$solution$ : solution actuelle}
			\Ensure{$pire\_voisin$}
			\Statex
			
			\Function{worst\_improver}{$\mathbf{solution}$, $\mathbf{voisins}$}
			\State {$meilleur\_voisin$ $\gets$ {$NULL$}}
			\State {$cur\_cost$ $\gets$ {$-1 $}}
			
			\For { \textbf{each} $voisin$ \textbf{in} $voisins$}    
			                
			\If{$cost(voisin) < cost(solution)  $ \textbf{and}  $cost(voisin) > cur\_cost$  }  
			\State {$pire\_voisin$ $\gets$ {$voisin$}}
			\State {$cur\_cost$ $\gets$ {$cost(voisin)$}}
			\EndIf
			\EndFor
			\State \Return {$pire\_voisin$}
			\EndFunction
			
		\end{algorithmic}
	\end{algorithm}
	
\end{itemize}

En utilisant les deux relations de voisinage pour chacun on six algos de choix de voisin pour la descente :
\begin{enumerate}
	\item best\_improver\_swap
	\item first\_improver\_swap
	\item worst\_improver\_swap
	\item best\_improver\_2opt
	\item first\_improver\_2opt
	\item worst\_improver\_2opt
\end{enumerate}

\subsubsection{Descente complète}
On part d’une solution initiale. Tant que la solution courante n’est pas un optimum local, on génère un voisin selon le couple (voisinage, pivot) pour remplacer la solution courante. Voici son pseudo code Aglo~\ref{algo:descente} :

	\begin{algorithm}[H]
	\caption{Descente complète}
	\label{algo:descente}
	\begin{algorithmic}[1]
		\Require{$algo$ : l'un de 6 algo de choix de voisin}
		\Require{$solution$ : solution initiale}
		\Ensure{$solution\_final$}
		\Statex
		
		\Function{descente}{$\mathbf{solution}$, $\mathbf{algo}$}
		\State {$solution\_final$ $\gets$ {$solution$}}
		\State {$voisins$ $\gets$ {$generate\_voisins(solution)$}} \Comment{avec swap ou 2-opt selon le cas}
		\State {$new\_solution$ $\gets$ {$algo(solution,voisins)$}}
		
		\While{$new\_solution != NULL$}
			\State {$solution\_final$ $\gets$ {$new\_solution$}}
			\State {$voisins$ $\gets$ {$generate\_voisins(solution\_final)$}}
			\State {$new\_solution$ $\gets$ {$algo(solution\_final,voisins)$}}
		\EndWhile
		
		\State \Return {$solution\_final$}
		\EndFunction
		
		
	\end{algorithmic}
\end{algorithm}

\subsection{Iterated Local Search(ILS)}
ILS (Algo~\ref{algo:ils}) utilise la descente. A chaque fin de descente, tant que le critère d’arrêt n’est pas atteint un nombre de perturbations sera appliqué à la meilleure solution rencontrée depuis le début de l’exécution. En fin d’exécution
la solution retournée sera la meilleure rencontrée. 


Le critère d'arrêt utilisé est le nombre d’évaluation maximal.

\begin{algorithm}[H]
	\caption{ILS}
	\label{algo:ils}
	\begin{algorithmic}[1]
		\Require{$solution$ : solution initiale}
		\Require{$algo$ : l'un de 6 algo de choix de voisin}
		\Require{$nb\_pertubations$ : nombre de perturbations}
		\Require{$max\_eval$ : nombre d’évaluation maximal}
		\Ensure{$best\_sol$}
		\Statex
		
		\Function{ils}{$\mathbf{solution}$, $\mathbf{algo}$, $\mathbf{nb\_pertubations}$, $\mathbf{max\_eval}$}
		
		\State {$nombre\_evaluations$ $\gets$ {$0$}} \Comment{Variable globale, incrémentée à chaque évaluation}
		
		\State {$best\_sol$ $\gets$ {$solution$}}
		\State {$cur\_sol$ $\gets$ {$solution$}}
	
		\While{$nombre\_evaluations < max\_eval$}
		\State {$new\_sol$ $\gets$ {$descente(cur\_sol,algo)$}}
		\If{$cost(new\_sol) < cost(best\_sol)$}
			\State {$best\_sol$ $\gets$ {$new\_sol$}}
		\EndIf  
		\State {$cur\_sol$ $\gets$ {$apply\_pertubations(best\_sol,nb\_pertubations)$}}
		\EndWhile
		
		\State \Return {$best\_sol$}
		\EndFunction
		
		
	\end{algorithmic}
\end{algorithm}



\subsection{Sampled Walk (SW)}
SW (Algo~\ref{algo:sw}) est une recherche locale dont le principe est de générer $\lambda$ voisins à chaque étape de la recherche et de sélectionner celui au meilleur score.
Le critère d'arrêt utilisé est le nombre d’évaluation maximal.

\begin{algorithm}[H]
	\caption{SW}
	\label{algo:sw}
	\begin{algorithmic}[1]
		\Require{$solution$ : solution initiale}
		\Require{$\lambda$ : nombre de voisins à générer }
		\Require{$max\_eval$ : nombre d’évaluation maximal}
		\Ensure{$best\_sol$}
		\Statex
		
		\Function{sw}{$\mathbf{solution}$, $\mathbf{algo}$, $\mathbf{nb\_pertubations}$, $\mathbf{max\_eval}$}
		
		\State {$nombre\_evaluations$ $\gets$ {$0$}} \Comment{Variable globale, incrémentée à chaque évaluation}
		
		\State {$best\_sol$ $\gets$ {$solution$}}
		
		
		\While{$nombre\_evaluations < max\_eval$}
		\State {$new\_sol$ $\gets$ {$generate\_and\_choice\_best(best\_sol,\lambda)$}}
		\If{$cost(new\_sol) < cost(best\_sol)$}
		\State {$best\_sol$ $\gets$ {$new\_sol$}}
		\EndIf  
		\EndWhile
		
		\State \Return {$best\_sol$}
		\EndFunction
		
		
	\end{algorithmic}
\end{algorithm}

\subsection{Algorithme génétique : Bonus}
J'ai choisi de faire l'algorithme génétique pour varier comme on a fait que des recherches. locales.
\newline
De façon générale un algorithme génétique pour la résolution d’un problème d’optimisation fonctionne sur le principe suivant.
\begin{itemize}
	\item \textbf{Création de la Population Initiale} :

Génération d'un groupe d'individus représentant différentes solutions possibles.

\item \textbf{Sélection des Parents }:

Choix d'individus parents, souvent basé sur leur performance (fitness).

\item \textbf{Croisement (Crossover) }:

Les parents se reproduisent en échangeant une partie de leurs caractéristiques pour créer des enfants.

\item \textbf{Mutation :}

Les enfants peuvent subir des modifications aléatoires pour introduire de la diversité.

\item \textbf{Sélection des Survivants (Fitness) :}

Évaluation de la performance de la population totale et sélection des individus les plus adaptés pour survivre.

\item \textbf{Itération }:

Répétition des étapes de reproduction, mutation, et sélection sur plusieurs générations.
\end{itemize}
